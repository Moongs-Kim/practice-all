[CAS - 동기화와 원자적 연산]

<원자적 연산 - 소개>
컴퓨터 과학에서 사용하는 원자적 연산(atomic operation)의 의미는 해당 연산이 더 이상 나눌 수 없는
단위로 수행된다는 것을 의미한다. 즉, 원자적 연산은 중단되지 않고, 다른 연산과 간섭 없이 완전히 실행되거나
전혀 실행되지 않는 성질을 가지고 있다. 쉽게 말해 멀티스레드 상황에서 다른 스레드의 간섭 없이 안전하게
처리되는 연산이라는 뜻이다.

== 원자적 연산 예 ==
1) 원자적 연산
    int i = 0
    위 연산은 둘로 쪼갤 수 없는 원자적 연산이다.
    왜냐하면 이 연산은 단 하나의 순서로 실행되기 때문이다.
    1. 오른쪽에 있는 0의 값을 왼쪽의 i 변수에 대입한다.

2) 비 원자적 연산
    i = i + 1, i++
    위 연산은 원자적 연산이 아니다.
    왜냐하면 이 연산은 다음 순서로 나누어 실행되기 때문이다.
    1. 오른쪽에 있는 i의 값을 읽는다. (i의 값은 10이라고 가정)
    2. 읽은 10에 1을 더해서 11을 만든다.
    3. 더한 11을 왼쪽의 i 변수에 대입한다.

★원자적 연산은 멀티스레드 상황에서 아무런 문제가 발생하지 않는다. 하지만 원자적 연산이 아닌 경우에는
synchronized 블럭이나 Lock 등을 사용해서 안전한 임계 영역을 만들어야 한다.

★공유 가능한 자원에 원자적이지 않은 연산을 사용하면 멀티스레드 상황에 문제가 될 수 있다.
★연산 자체가 나누어진 경우에는 synchronized 블럭이나 Lock 등을 사용해서 안전한 임계 영역을 만들어야 한다.

<원자적 연산 - AtomicInteger>
자바는 멀티스레드 상황에서 안전하게 증가 연산을 수행할 수 있는 AtomicInteger 라는 클래스를 제공한다.
이름 그대로 원자적인 Integer 라는 뜻이다.

- new AtomicInteger(0): 초기값을 지정한다. 생략하면 0 부터 시작한다.
- incrementAndGet(): 값을 하나 증가하고 증가된 결과를 반환한다.
- get(); 현재 값을 반환한다.

AtomicInteger는 멀티스레드 상황에 안전하고 또 다양한 값 증가, 감소 연산을 제공한다. 특정 값을 증가하거나
감소해야 하는데 여러 스레드가 해당 값을 공유해야 한다면, AtomicInteger를 사용하면 된다.

※참고: AtomicInteger, AtomicLong, AtomicBoolean등 다양한 AtomicXxx 클래스가 존재한다.

<원자적 연산 - 성능 테스트>
- 자바가 제공하는 AtomicInteger를 사용하면, 멀티스레드 상황에 안전하게 사용할 수 있다.
- 성능도 synchronized, Lock(ReentrantLock)을 사용하는 경우보다 1.5 ~ 2배 정도 빠르다.

== AtomicInteger가 성능이 더 빠른 이유 ==
i++ 연산은 원자적인 연산이 아니다. 따라서 synchronized, Lock(ReentrantLock)와 같은 락을 통해
안전한 임계 영역을 만들어야 한다.
하지만 AtomicInteger가 제공하는 incrementAndGet() 메서드는 락을 사용하지 않고, 원자적 연산을 만들어 낸다.

<CAS 연산>
※참고
CAS 연산은 심화 내용이다. 이해가 어렵 다면 가볍게 듣고 넘어가도 괜찮다. 왜냐하면 직접 CAS 연산을 사용하는
경우는 거의 없기 때문이다. 대부분 복잡한 동시성 라이브러리들이 CAS 연산을 사용한다.
AtomicInteger와 같은 CAS 연산을 사용하는 라이브러리들을 잘 사용하는 정도면 충분하다.

== 락 기반 방식의 문제점 ==
락은 특정 자원을 보호하기 위해 스레드가 해당 자원에 대해 접근하는 것을 제한한다.
락이 걸려 있는 동안 다른 스레드들은 해당 자원에 접근할 수 없고, 락이 해제될 때까지 대기해야 한다.
또한 락 기반 접근에서는 락을 획득하고 해제하는 데 시간이 소요된다.

EX)
1. 락이 있는지 확인한다.
2. 락을 획득하고 임계 영역에 들어간다.
3. 작업을 수행한다.
4. 락을 반납한다.

락을 사용하는 방식은 직관적이지만 상대적으로 무거운 방식이다.

== CAS ==
위와 같은 문제를 해결하기 위해 락을 걸지 않고 원자적인 연산을 수행할 수 있는 방법이 CAS 이다.
CAS(Compare-And-Swap, Compare-And-Set) 연산이라 한다.
이 방법은 락을 사용하지 않기 때문에 락 프리(lock-free) 기법이라 한다.
CAS 연산은 락을 완전히 대체하는 것은 아니다. '작은 단위의 일부 영역'에 적용 할 수 있다.
기본은 락을 사용하고, 특별한 경우에 CAS를 적용할 수 있다고 생각하면 된다.

== compareAndSet(0,1) ==
atomicInteger가 가지고 있는 값이 현재 0이면 이 값을 1로 변경하라는 매우 단순한 메서드이다.
- atomicInteger의 값이 현재 0이라면 atomicInteger의 값은 1로 변경된다. 이 경우 true를 반환한다.
- atomicInteger의 값이 현재 0아니라면 atomicInteger의 값은 변경되지 않는다.
  이 경우 false를 반환한다.

여기서 가장 중요한 내용이, '이 메서드는 원자적으로 실행' 된다는 점이다.
그리고 이 메서드가 제공하는 기능이 바로 CAS(compareAndSet) 연산이다.

== CAS - 실행 순서 및 원리 ==
- compareAndSet(0,1)을 호출한다. 매개변수의 왼쪽이 기대하는 값, 오른쪽이 변경하는 값이다.
- CAS 연산은 메모리에 있는 값이 기대하는 값이라면 원하는 값으로 변경한다.
- 메모리에 있는 value의 값이 0이므로 1로 변경할 수 있다.
- 그런데 생각해보면 이 명령어는 2개로 나누어진 명령이다. 따라서 원자적인 연산이 아니다.
  1. 먼저 메인 메모리에 있는 값을 확인한다.
  2. 해당 값이 기대하는 값(0)이라면 원하는 값(1)으로 변경한다.

★CPU 하드웨어의 지원
CAS 연산은 원자적이지 않은 두 개의 연산을 CPU 하드웨어 차원에서 특별하게 하나의 원자적인 연산으로 묶어서
제공하는 기능이다. 이것은 소프트웨어가 제공하는 기능이 아니라 하드웨어가 제공하는 기능이다.
대부분의 현대 CPU 들은 CAS 연산을 위한 명령어를 제공한다.

CPU는 다음 두 과정을 묶어서 하나의 원자적인 명령으로 만들어 버린다. 따라서 중간에 다른 스레드가 개입할 수 없다.
1. 메모리 값(value)을 확인한다.
2. 읽은 값이 0이면 1로 변경한다.

CPU는 두 과정을 하나의 원자적인 명령으로 만들기 위해 1번과 2번 사이에 다른 스레드가 메모리 값(value)을
변경하지 못하게 막는다. 참고로 1번과 2번 사이의 시간은 CPU 입장에서 보면 아주 잠깐 찰나의 순간이다.
그래서 성능에 큰 영향을 끼치지 않는다.

== CAS - 락을 일부 대체할 수 있는 이유 ==
CAS 연산을 사용하면 여러 스레드가 같은 값을 사용하는 상황에서도 락을 걸지 않고, 안전하게 값을
증가할 수 있다.

CAS를 사용하면 락을 사용하지 않지만, 대신에 다른 스레드가 값을 먼저 증가해서 문제가 발생하는 경우
루프를 돌며 재시도를 하는 방식을 사용한다.

- 동작 방식
1. 현재 변수의 값을 읽어온다.
2. 변수의 값을 1 증가시킬 때, 원래 값이 같은지 확인한다. (CAS 연산 사용)
3. 동일하다면 증가된 값을 변수에 저장하고 종료한다.
4. 동일하지 않다면 다른 스레드가 값을 중간에 변경한 것이므로, 다시 처음으로 돌아가 위 과정을 반복한다.

두 스레드가 동시에 실행되면서 문제가 발생하는 상황을 스레드가 충돌했다고 표현한다.
이 과정에서 충돌이 발생할 때마다 반복해서 다시 시도하므로, 결과적으로 락 없이 데이터를 안전하게 변경할 수 있다.
CAS를 사용하는 방식은 충돌이 드물게 발생하는 환경에서는 락을 사용하지 않으므로 높은 성능을 발휘할 수 있다.
이는 락을 사용하는 방식과 비교했을 때, 스레드가 락을 획득하기 위해 대기하지 않기 때문에 대기 시간과 오버헤드가
줄어드는 장점이 있다.

그러나 충돌이 빈번하게 발생하는 환경에서는 성능에 문제가 될 수 있다. 여러 스레드가 자주 동시에 동일한
변수의 값을 변경하려고 시도할 때, CAS는 자주 실패하고 재시도해야 하므로 성능 저하가 발생할 수 있다.
이런 상황에서는 반복문을 계속 돌기 때문에 CPU 자원을 많이 소모하게 된다.

* CAS에 대한 내 생각
CAS는 쉽게
1. CPU 에서 지원. 이걸 통해 원자적이지 않은 연산을 원자적으로 만들 수 있음
2. 값을 확인하고 확인 한 값과 확인 전 값이 같은지 여부를 판단해 값 증감 여부 판단
   값이 바뀌었다면 다른 스레드에서 바꾼것이므로 다시 변경 시도
★값을 변경하는건 CPU 에서 하나의 스레드만 변경할 수 있게 막으므로 동시에 값을 변경하는것은 불가

* 멀티스레드에 제어 대한 내 생각(정리)
1. 공유 자원에 여러 스레드가 동시에 접근 가능한 것이 문제
2. 사실 접근까지는 문제 없음, 값을 변경하는 것이 문제
   읽기는 일반적으로 문제되지 않지만, 동시에 값을 변경 하는 경우 문제가 발생한다.

따라서 동시성 제어를 위해서는
1. 지역변수는 개별 스택영역에 존재하므로 공유 자원이 아님(접근 자체가 불가)
2. final 키워드는 값을 변경할 수 없으므로 동시 접근해도 문제 없음
   하지만 객체 내부의 값을 바꿀 수 있으면 문제 가능
   따라서 불변일 경우에 스레드 안전
3. 락을 통한 접근 제어, 한번에 하나의 스레드만 작업할 수 있게 제어
4. 원자적 연산은 여러 스레드가 동시에 접근해도 한번만 작업하므로
   동시 접근해도 상관없음
   CPU 차원에서 직렬화되어 처리되서 중간에 끼어들기가 불가능 하다함
5. CAS는 하드웨어 수준에서 락 없이 동시성 문제를 해결하는 기법
   기대 값이 일치할 때만 값을 교체

== CAS(Compare-And-Swap)와 락(Lock) 방식의 비교 ==
1) 락(Lock) 방식
- 비관적(pessimistic) 접근법
- 데이터에 접근하기 전에 항상 락을 획득
- 다른 스레드의 접근을 막음
- '다른 스레드가 방해할 것이다'라고 가정

2) CAS(Compare-And-Swap) 방식
- 낙관적(optimistic) 접근법
- 락을 사용하지 않고 데이터에 바로 접근
- 충돌이 발생하면 그때 재시도
- '대부분의 경우 충돌이 없을 것이다'라고 가정

* 정리
충돌이 많이 없는 경우에 CAS 연산이 빠르다.

== 충돌이 많이 발생하지 않는 연산은? ==
간단한 CPU 연산은 너무 빨리 처리되기 때문에 충돌이 자주 발생하지 않는다.
충돌이 발생하기도 전에 이미 연산을 완료하는 경우가 더 많다.

즉, 간단한 CPU 연산에는 락 보다는 CAS를 사용하는 것이 효과적이다.

<CAS 락 구현>
CAS는 단순한 연산 뿐만 아니라, 락을 구현하는데 사용할 수도 있다.

원자적인 연산은 스레드 입장에서 쪼갤 수 없는 하나의 연산이다. 따라서 여러 스레드가 동시에 실행해도 안전하다.
이렇게 CAS를 사용해서 원자적인 연산을 만든 덕분에 무거운 동기화 작업 없이 아주 가벼운 락을 만들 수 있다.
동기화 락을 사용하는 경우 스레드가 락을 획득하지 못하면 BLOCKED, WAITING 등으로 상태가 변한다.
그리고 또 대기 상태의 스레드를 깨워야 하는 무겁고 복잡한 과정이 추가로 들어간다.
따라서 성능이 상대적으로 느릴 수 있다.
반면 CAS를 활용한 락 방식은 사실 락이 없다. 단순히 while 문을 반복할 뿐이다.
따라서 대기하는 스레드도 RUNNABLE 상태를 유지하면서 가볍고 빠르게 작동할 수 있다.

하지만 이렇게 반복문과 CAS를 사용해서 락을 대체하는 방식에도 단점이 있다.
바로 RUNNABLE 상태로 락을 획들할 때 까지 while 문을 반복하는 문제가 있다.
따라서 락을 기다리는 스레드가 CPU를 계속 사용하면서 대기하는 것이다.
따라서 RUNNABLE로 살려둔 상태에서 계속 락 획득을 반복 체크하는 것이 더 효율적인
경우에 이런 방식을 사용해야 한다. 이 방식은 스레드의 상태가 변경되지 않기 때문에
매우 빠르게 락을 획득하고, 또 바로 실행할 수 있는 장점이 있다.

어떤 경우가 좋은가?
안전한 임계 영역이 필요하지만, 연산이 길지 않고 매우매우매우! 짧게 끝날 때 사용해야 한다.
예를 들어 숫자 값의 증가, 자료 구조의 데이터 추가와 같이 CPU 사이클이 금방 끝나는 연산에
사용하면 효과적이다.
반면 데이터베이스의 결과를 대기한다거나, 다른 서버의 요청을 기다린다거나 하는 것 처럼
오래 기다리는 작업에 사용하면 CPU를 계속 사용하며 기다리는 최악의 결과가 나올 수도 있다.

== 스핀 락 용어 ==
스레드가 락이 해제되기를 기다리면서 반복문을 통해 계속해서 확인하는 모습이 마치 제자리에서 회전(spin)하는
것처럼 보인다. 그래서 이런 방식을 '스핀 락'이라고도 부른다. 그리고 이런 방식에서 스레드가 락을 획득 할 때
까지 대기하는 것을 스핀 대기(spin-wait) 또는 CPU 자원을 계속 사용하면서 바쁘게 대기한다고 해서 바쁜 대기(busy-wait)
라 한다.
이런 스핀 락 방식은 아주 짧은 CPU 연산을 수행할 때 사용해야 효율적이다. 잘못 사용하면 오히려 CPU 자원을 더
많이 사용할 수 있다.
정리하면 '스핀 락'이라는 용어는, 락을 획득하기 위해 자원을 소모하면서 반복적으로 확인(스핀)하는 락 메커니즘을
의미한다. 그리고 이런 스핀 락은 CAS를 사용해서 구현할 수 있다.

<정리 락 vs CAS 사용 방식>
동기화 락(synchronized,Lock(ReentrantLock))을 사용하는 방식과 CAS를 활용하는 락 프리 방식의 장단
점을 비교

CAS의 장점
1. 낙관적 동기화: 락을 걸지 않고도 값을 안전하게 업데이트할 수 있다. CAS는 충돌이 자주 발생하지 않을 것이라고
   가정한다. 이는 충돌이 적은 환경에서 높은 성능을 발휘한다.
2. 락 프리(Lock-Free): CAS는 락을 사용하지 않기 때문에, 락을 획득하기 위해 대기하는 시간이 없다. 따라서 스
   레드가 블로킹되지 않으며, 병렬 처리가 더 효율적일 수 있다.

CAS의 단점
1. 충돌이 빈번한 경우: 여러 스레드가 동시에 동일한 변수에 접근하여 업데이트를 시도할 때 충돌이 발생할 수 있다.
   충돌이 발생하면 CAS는 루프를 돌며 재시도해야 하며, 이에 따라 CPU 자원을 계속 소모할 수 있다. 반복적인 재
   시도로 인해 오버헤드가 발생할 수 있다.
2. 스핀락과 유사한 오버헤드: CAS는 충돌 시 반복적인 재시도를 하므로, 이 과정이 계속 반복되면 스핀락과 유사한
   성능 저하가 발생할 수 있다. 특히 충돌 빈도가 높을수록 이런 현상이 두드러진다.

동기화 락의 장점
1. 충돌 관리: 락을 사용하면 하나의 스레드만 리소스에 접근할 수 있으므로 충돌이 발생하지 않는다. 여러 스레드가
   경쟁할 경우에도 안정적으로 동작한다.
2. 안정성: 복잡한 상황에서도 락은 일관성 있는 동작을 보장한다.
3. 스레드 대기: 락을 대기하는 스레드는 CPU를 거의 사용하지 않는다.

동기화 락의 단점
1. 락 획득 대기 시간: 스레드가 락을 획득하기 위해 대기해야 하므로, 대기 시간이 길어질 수 있다.
2. 컨텍스트 스위칭 오버헤드: 락을 사용하면, 락 획득을 대기하는 시점과 또 락을 획득하는 시점에 스레드의 상태가
   변경된다. 이때 컨텍스트 스위칭이 발생할 수 있으며, 이로 인해 오버헤드가 증가할 수 있다.


